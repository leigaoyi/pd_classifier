{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "SA_raw_data = loadmat('sub_a.mat')\n",
    "SA_signals = SA_raw_data['responses']\n",
    "SA_label = SA_raw_data['is_stimulate']\n",
    "SA_data = []\n",
    "SA_target = []\n",
    "for i in range(12):\n",
    "    for j in range(85):\n",
    "        if SA_label[i, j] == 1:\n",
    "            SA_data.append(SA_signals[i, :, :, j].reshape(-1, 64))\n",
    "            SA_target.append(SA_label[i, j])\n",
    "            SA_data.append(SA_signals[i, :, :, j].reshape(-1, 64))\n",
    "            SA_target.append(SA_label[i, j])\n",
    "            SA_data.append(SA_signals[i, :, :, j].reshape(-1, 64))\n",
    "            SA_target.append(SA_label[i, j])\n",
    "            SA_data.append(SA_signals[i, :, :, j].reshape(-1, 64))\n",
    "            SA_target.append(SA_label[i, j])\n",
    "        SA_data.append(SA_signals[i, :, :, j].reshape(-1, 64))\n",
    "        SA_target.append(SA_label[i, j])\n",
    "SA_data = np.array(SA_data)\n",
    "SA_target = np.array(SA_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(SA_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SB_raw_data = loadmat('sub_b.mat')\n",
    "SB_signals = SB_raw_data['responses']\n",
    "SB_label = SB_raw_data['is_stimulate']\n",
    "SB_data = []\n",
    "SB_target = []\n",
    "for i in range(12):\n",
    "    for j in range(85):\n",
    "        if SB_label[i, j] == 1:\n",
    "            SB_data.append(SB_signals[i, :, :, j].reshape(-1, 64))\n",
    "            SB_target.append(SB_label[i, j])\n",
    "            SB_data.append(SB_signals[i, :, :, j].reshape(-1, 64))\n",
    "            SB_target.append(SB_label[i, j])\n",
    "            SB_data.append(SB_signals[i, :, :, j].reshape(-1, 64))\n",
    "            SB_target.append(SB_label[i, j])\n",
    "            SB_data.append(SB_signals[i, :, :, j].reshape(-1, 64))\n",
    "            SB_target.append(SB_label[i, j])\n",
    "        SB_data.append(SB_signals[i, :, :, j].reshape(-1, 64))\n",
    "        SB_target.append(SB_label[i, j])\n",
    "SB_data = np.array(SB_data)\n",
    "SB_target = np.array(SB_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850\n",
      "850\n"
     ]
    }
   ],
   "source": [
    "def get_num(array):\n",
    "    num_0=0\n",
    "    num_1=0\n",
    "    for i in range(len(array)):\n",
    "        if array[i]==0:\n",
    "            num_0+=1\n",
    "        else:\n",
    "            num_1+=1\n",
    "    return num_0,num_1\n",
    "SA_0,SA_1=get_num(SB_target)\n",
    "print(SA_0)\n",
    "print(SA_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1201\n",
      "1179\n",
      "499\n",
      "521\n"
     ]
    }
   ],
   "source": [
    "y_train_0,y_train_1=get_num(y_train)\n",
    "print(y_train_0)\n",
    "print(y_train_1)\n",
    "y_test_0,y_test_1=get_num(y_test)\n",
    "print(y_test_0)\n",
    "print(y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 240, 64)\n",
      "(1700,)\n",
      "(1700, 240, 64)\n",
      "(1700,)\n"
     ]
    }
   ],
   "source": [
    "print(SA_data.shape)\n",
    "print(SA_target.shape)\n",
    "print(SB_data.shape)\n",
    "print(SB_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=np.concatenate((SA_data,SB_data),axis=0)\n",
    "all_target=np.concatenate((SA_target,SB_target),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import _pickle as cp\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data, all_target, test_size=0.3, random_state=42)\n",
    "y_train=np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_SENSOR_CHANNELS = 64 #通道数目\n",
    "NUM_CLASSES = 2       #类别数\n",
    "BATCH_SIZE = 64\n",
    "NUM_FILTERS = 64\n",
    "FILTER_SIZE = 5\n",
    "NUM_UNITS_LSTM = 128\n",
    "STRIDE_SIZE=3 #卷积步长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv1D_1 (Conv1D)            (None, 79, 64)            20544     \n",
      "_________________________________________________________________\n",
      "Conv1D_2 (Conv1D)            (None, 25, 64)            20544     \n",
      "_________________________________________________________________\n",
      "Conv1D_3 (Conv1D)            (None, 7, 64)             20544     \n",
      "_________________________________________________________________\n",
      "LSTM_1 (LSTM)                (None, 7, 128)            98816     \n",
      "_________________________________________________________________\n",
      "LSTM_2 (LSTM)                (None, 7, 128)            131584    \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 2)                 1794      \n",
      "=================================================================\n",
      "Total params: 293,826\n",
      "Trainable params: 293,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "rmp = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_SIZE, strides=STRIDE_SIZE,activation='relu', kernel_initializer='orthogonal',\n",
    "                 input_shape=(240, NB_SENSOR_CHANNELS), \n",
    "                 name='Conv1D_1'))\n",
    "model.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_SIZE,strides=STRIDE_SIZE, activation='relu', kernel_initializer='orthogonal', \n",
    "                 name='Conv1D_2'))\n",
    "model.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_SIZE,strides=STRIDE_SIZE, activation='relu', kernel_initializer='orthogonal', \n",
    "                 name='Conv1D_3'))\n",
    "#model.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_SIZE, strides=STRIDE_SIZE, activation='relu', kernel_initializer='orthogonal',\n",
    "#                 name='Conv1D_4'))\n",
    "model.add(LSTM(NUM_UNITS_LSTM, return_sequences=True, kernel_initializer='orthogonal', \n",
    "               name='LSTM_1'))\n",
    "model.add(LSTM(NUM_UNITS_LSTM, return_sequences=True, kernel_initializer='orthogonal', \n",
    "               name='LSTM_2'))\n",
    "model.add(Flatten(name='Flatten'))\n",
    "model.add(Dropout(0.5, name='dropout'))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax', kernel_initializer='orthogonal', \n",
    "                name='Output'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rmp, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "2380/2380 [==============================] - 11s 5ms/step - loss: 0.5867 - accuracy: 0.6962\n",
      "Epoch 2/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.3113 - accuracy: 0.8689\n",
      "Epoch 3/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.1851 - accuracy: 0.9202\n",
      "Epoch 4/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.1247 - accuracy: 0.9555\n",
      "Epoch 5/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0975 - accuracy: 0.9626\n",
      "Epoch 6/100\n",
      "2380/2380 [==============================] - 6s 2ms/step - loss: 0.0526 - accuracy: 0.9811\n",
      "Epoch 7/100\n",
      "2380/2380 [==============================] - 6s 2ms/step - loss: 0.0630 - accuracy: 0.9794\n",
      "Epoch 8/100\n",
      "2380/2380 [==============================] - 6s 2ms/step - loss: 0.0550 - accuracy: 0.9811\n",
      "Epoch 9/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0348 - accuracy: 0.9895\n",
      "Epoch 10/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0270 - accuracy: 0.9903\n",
      "Epoch 11/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0199 - accuracy: 0.9924\n",
      "Epoch 12/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0442 - accuracy: 0.9903\n",
      "Epoch 13/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0306 - accuracy: 0.9887\n",
      "Epoch 14/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0271 - accuracy: 0.9912\n",
      "Epoch 15/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0046 - accuracy: 0.9992\n",
      "Epoch 16/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0269 - accuracy: 0.9924\n",
      "Epoch 17/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0724 - accuracy: 0.9807\n",
      "Epoch 18/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0169 - accuracy: 0.9950\n",
      "Epoch 19/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0203 - accuracy: 0.9941\n",
      "Epoch 20/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0131 - accuracy: 0.9958\n",
      "Epoch 21/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0186 - accuracy: 0.9945\n",
      "Epoch 22/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0121 - accuracy: 0.9966\n",
      "Epoch 23/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0225 - accuracy: 0.9933\n",
      "Epoch 24/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0028 - accuracy: 0.9983\n",
      "Epoch 25/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0341 - accuracy: 0.9903\n",
      "Epoch 26/100\n",
      "2380/2380 [==============================] - 6s 2ms/step - loss: 0.0278 - accuracy: 0.9899\n",
      "Epoch 27/100\n",
      "2380/2380 [==============================] - 6s 2ms/step - loss: 0.0114 - accuracy: 0.9958\n",
      "Epoch 28/100\n",
      "2380/2380 [==============================] - 6s 2ms/step - loss: 0.0063 - accuracy: 0.9979\n",
      "Epoch 29/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0397 - accuracy: 0.9912\n",
      "Epoch 30/100\n",
      "2380/2380 [==============================] - 6s 2ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 31/100\n",
      "2380/2380 [==============================] - 6s 2ms/step - loss: 0.0220 - accuracy: 0.9937\n",
      "Epoch 32/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0168 - accuracy: 0.9933\n",
      "Epoch 33/100\n",
      "2380/2380 [==============================] - 6s 3ms/step - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 34/100\n",
      "2380/2380 [==============================] - 6s 2ms/step - loss: 0.0121 - accuracy: 0.9962\n",
      "Epoch 35/100\n",
      "2380/2380 [==============================] - 6s 3ms/step - loss: 0.0202 - accuracy: 0.9941\n",
      "Epoch 36/100\n",
      "2380/2380 [==============================] - 6s 3ms/step - loss: 0.0174 - accuracy: 0.9954\n",
      "Epoch 37/100\n",
      "2380/2380 [==============================] - 6s 3ms/step - loss: 0.0059 - accuracy: 0.9975: 2s - l\n",
      "Epoch 38/100\n",
      "2380/2380 [==============================] - 6s 3ms/step - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 39/100\n",
      "2380/2380 [==============================] - 6s 2ms/step - loss: 0.0164 - accuracy: 0.9937\n",
      "Epoch 40/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0117 - accuracy: 0.9975\n",
      "Epoch 41/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 7.6851e-04 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 1.6433e-05 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 3.9482e-06 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0043 - accuracy: 0.9992\n",
      "Epoch 45/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0171 - accuracy: 0.9933\n",
      "Epoch 46/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 1.6048e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 1.6160e-05 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 4.1649e-06 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 6.6668e-07 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0380 - accuracy: 0.9941\n",
      "Epoch 51/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0049 - accuracy: 0.9975\n",
      "Epoch 52/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0089 - accuracy: 0.9966\n",
      "Epoch 53/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0012 - accuracy: 0.9992\n",
      "Epoch 54/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 2.8553e-05 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 2.0415e-06 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0208 - accuracy: 0.9966\n",
      "Epoch 57/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0022 - accuracy: 0.9996\n",
      "Epoch 58/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 59/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0134 - accuracy: 0.9962\n",
      "Epoch 60/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0086 - accuracy: 0.9966\n",
      "Epoch 61/100\n",
      "2380/2380 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.99 - 5s 2ms/step - loss: 0.0133 - accuracy: 0.9962\n",
      "Epoch 62/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0046 - accuracy: 0.9979\n",
      "Epoch 63/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0157 - accuracy: 0.9958: 2s\n",
      "Epoch 64/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 65/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0182 - accuracy: 0.9950\n",
      "Epoch 66/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0095 - accuracy: 0.9962\n",
      "Epoch 67/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 5.2317e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0105 - accuracy: 0.9975\n",
      "Epoch 69/100\n",
      "2380/2380 [==============================] - 6s 2ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 70/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0064 - accuracy: 0.9987\n",
      "Epoch 71/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 2.7808e-05 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0021 - accuracy: 0.9992\n",
      "Epoch 73/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0065 - accuracy: 0.9975\n",
      "Epoch 74/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0062 - accuracy: 0.9987\n",
      "Epoch 75/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 3.8888e-05 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 5.0270e-06 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 4.9743e-07 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0031 - accuracy: 0.9996\n",
      "Epoch 79/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0258 - accuracy: 0.9937\n",
      "Epoch 80/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0034 - accuracy: 0.9983\n",
      "Epoch 81/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 1.3020e-05 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 1.6453e-06 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 4.2653e-07 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0208 - accuracy: 0.9950\n",
      "Epoch 85/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 2.2817e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 8.1755e-06 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 1.4333e-06 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 4.0802e-07 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 90/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0096 - accuracy: 0.9975\n",
      "Epoch 91/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 3.5662e-05 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 5.2280e-06 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "2380/2380 [==============================] - ETA: 0s - loss: 7.0651e-07 - accuracy: 1.00 - 5s 2ms/step - loss: 7.0355e-07 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0198 - accuracy: 0.9958\n",
      "Epoch 95/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0069 - accuracy: 0.9983\n",
      "Epoch 96/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0098 - accuracy: 0.9975\n",
      "Epoch 97/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0108 - accuracy: 0.9975\n",
      "Epoch 98/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0145 - accuracy: 0.9958\n",
      "Epoch 99/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0106 - accuracy: 0.9966\n",
      "Epoch 100/100\n",
      "2380/2380 [==============================] - 5s 2ms/step - loss: 0.0170 - accuracy: 0.9971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1eaeed5bbe0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=BATCH_SIZE,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest accauracy:\t0.9794 \n",
      "Running time: 0.7415946 Seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start =time.clock()\n",
    "test_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "test_true = np.argmax(y_test, axis=1)\n",
    "np.unique(test_pred)\n",
    "import sklearn.metrics as metrics\n",
    "print(\"\\tTest accauracy:\\t{:.4f} \".format(metrics.accuracy_score(test_true, test_pred)))\n",
    "end = time.clock()\n",
    "print('Running time: %s Seconds'%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv1D_1 (Conv1D)            (None, 79, 64)            20544     \n",
      "_________________________________________________________________\n",
      "Conv1D_2 (Conv1D)            (None, 25, 64)            20544     \n",
      "_________________________________________________________________\n",
      "Conv1D_3 (Conv1D)            (None, 7, 64)             20544     \n",
      "_________________________________________________________________\n",
      "Flatten1 (Flatten)           (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 128)               57472     \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout3 (Dropout)           (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 135,874\n",
      "Trainable params: 135,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "rmp = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_SIZE, strides=STRIDE_SIZE,activation='relu', kernel_initializer='orthogonal',\n",
    "                 input_shape=(240, NB_SENSOR_CHANNELS), \n",
    "                 name='Conv1D_1'))\n",
    "model2.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_SIZE,strides=STRIDE_SIZE, activation='relu', kernel_initializer='orthogonal', \n",
    "                 name='Conv1D_2'))\n",
    "model2.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_SIZE,strides=STRIDE_SIZE, activation='relu', kernel_initializer='orthogonal', \n",
    "                 name='Conv1D_3'))\n",
    "#model.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_SIZE, strides=STRIDE_SIZE, activation='relu', kernel_initializer='orthogonal',\n",
    "#                 name='Conv1D_4'))\n",
    "model2.add(Flatten(name='Flatten1'))\n",
    "model2.add(Dropout(0.5, name='dropout1'))\n",
    "model2.add(Dense(128, activation='softmax', kernel_initializer='orthogonal', \n",
    "                name='Dense1'))\n",
    "model2.add(Dropout(0.5, name='dropout2'))\n",
    "model2.add(Dense(128, activation='softmax', kernel_initializer='orthogonal', \n",
    "                name='Dense2'))\n",
    "model2.add(Dropout(0.5, name='dropout3'))\n",
    "model2.add(Dense(NUM_CLASSES, activation='softmax', kernel_initializer='orthogonal', \n",
    "                name='Output'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=rmp, metrics=['accuracy'])\n",
    "\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "2380/2380 [==============================] - 8s 3ms/step - loss: 0.6930 - accuracy: 0.5076\n",
      "Epoch 2/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.6924 - accuracy: 0.5227\n",
      "Epoch 3/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.6904 - accuracy: 0.5962\n",
      "Epoch 4/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.6884 - accuracy: 0.5992\n",
      "Epoch 5/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.6850 - accuracy: 0.6563\n",
      "Epoch 6/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.6804 - accuracy: 0.6794\n",
      "Epoch 7/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.6760 - accuracy: 0.6735\n",
      "Epoch 8/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.6684 - accuracy: 0.6849\n",
      "Epoch 9/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.6621 - accuracy: 0.6697\n",
      "Epoch 10/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.6537 - accuracy: 0.6840\n",
      "Epoch 11/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.6479 - accuracy: 0.6739\n",
      "Epoch 12/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.6390 - accuracy: 0.6933\n",
      "Epoch 13/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.6261 - accuracy: 0.7008\n",
      "Epoch 14/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.6215 - accuracy: 0.6950\n",
      "Epoch 15/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.6098 - accuracy: 0.7130\n",
      "Epoch 16/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.5976 - accuracy: 0.7021\n",
      "Epoch 17/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.5921 - accuracy: 0.7055\n",
      "Epoch 18/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.5840 - accuracy: 0.7013\n",
      "Epoch 19/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.5921 - accuracy: 0.6744\n",
      "Epoch 20/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.5802 - accuracy: 0.6761\n",
      "Epoch 21/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.5586 - accuracy: 0.7185: 1s - loss:\n",
      "Epoch 22/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.5597 - accuracy: 0.7038\n",
      "Epoch 23/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.5477 - accuracy: 0.7109\n",
      "Epoch 24/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.5432 - accuracy: 0.7105\n",
      "Epoch 25/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.5432 - accuracy: 0.6979: 0s - loss: 0.5\n",
      "Epoch 26/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.5528 - accuracy: 0.6975\n",
      "Epoch 27/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.5309 - accuracy: 0.7118\n",
      "Epoch 28/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.5395 - accuracy: 0.7059\n",
      "Epoch 29/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.5184 - accuracy: 0.7176\n",
      "Epoch 30/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.5326 - accuracy: 0.6903\n",
      "Epoch 31/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.5190 - accuracy: 0.6971\n",
      "Epoch 32/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.5220 - accuracy: 0.7017\n",
      "Epoch 33/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.5106 - accuracy: 0.7126\n",
      "Epoch 34/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.5065 - accuracy: 0.7139\n",
      "Epoch 35/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.5317 - accuracy: 0.6920\n",
      "Epoch 36/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.4941 - accuracy: 0.7239: 1s - los\n",
      "Epoch 37/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.5134 - accuracy: 0.7151\n",
      "Epoch 38/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.5279 - accuracy: 0.6987\n",
      "Epoch 39/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.5086 - accuracy: 0.7076\n",
      "Epoch 40/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.5231 - accuracy: 0.6954\n",
      "Epoch 41/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.4890 - accuracy: 0.7214\n",
      "Epoch 42/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.5118 - accuracy: 0.7008\n",
      "Epoch 43/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.5054 - accuracy: 0.7063\n",
      "Epoch 44/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.4864 - accuracy: 0.7202\n",
      "Epoch 45/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.5104 - accuracy: 0.7055\n",
      "Epoch 46/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.4910 - accuracy: 0.7181\n",
      "Epoch 47/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.4917 - accuracy: 0.7134\n",
      "Epoch 48/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.4997 - accuracy: 0.7055\n",
      "Epoch 49/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4885 - accuracy: 0.7101\n",
      "Epoch 50/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.4948 - accuracy: 0.7122\n",
      "Epoch 51/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.4964 - accuracy: 0.7164: 1s - loss: 0\n",
      "Epoch 52/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.4954 - accuracy: 0.7097\n",
      "Epoch 53/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.5098 - accuracy: 0.7013\n",
      "Epoch 54/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.5028 - accuracy: 0.7004\n",
      "Epoch 55/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4698 - accuracy: 0.7214\n",
      "Epoch 56/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4902 - accuracy: 0.7084\n",
      "Epoch 57/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4733 - accuracy: 0.7244\n",
      "Epoch 58/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.4998 - accuracy: 0.7071: 0s - loss: 0.4835 - accu\n",
      "Epoch 59/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.5066 - accuracy: 0.7080\n",
      "Epoch 60/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.4905 - accuracy: 0.7029\n",
      "Epoch 61/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4964 - accuracy: 0.6992\n",
      "Epoch 62/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.4882 - accuracy: 0.7130\n",
      "Epoch 63/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.5045 - accuracy: 0.7164\n",
      "Epoch 64/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.4836 - accuracy: 0.7067: 0s - loss: 0.4821 - accuracy\n",
      "Epoch 65/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.4951 - accuracy: 0.7038\n",
      "Epoch 66/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.4993 - accuracy: 0.7000\n",
      "Epoch 67/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4939 - accuracy: 0.7126\n",
      "Epoch 68/100\n",
      "2380/2380 [==============================] - 4s 2ms/step - loss: 0.4956 - accuracy: 0.7088\n",
      "Epoch 69/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4985 - accuracy: 0.7084\n",
      "Epoch 70/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4930 - accuracy: 0.6987\n",
      "Epoch 71/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4616 - accuracy: 0.7206\n",
      "Epoch 72/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.5072 - accuracy: 0.6992: 1s - loss: - ETA: 0s - loss: 0.5039 - accu\n",
      "Epoch 73/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.4889 - accuracy: 0.7038\n",
      "Epoch 74/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.4894 - accuracy: 0.6975\n",
      "Epoch 75/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4863 - accuracy: 0.6996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4832 - accuracy: 0.7231\n",
      "Epoch 77/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.4791 - accuracy: 0.7118\n",
      "Epoch 78/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4852 - accuracy: 0.7109\n",
      "Epoch 79/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4588 - accuracy: 0.7239\n",
      "Epoch 80/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4767 - accuracy: 0.7244\n",
      "Epoch 81/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4923 - accuracy: 0.6950\n",
      "Epoch 82/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4712 - accuracy: 0.7168\n",
      "Epoch 83/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4730 - accuracy: 0.7084\n",
      "Epoch 84/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4861 - accuracy: 0.7176\n",
      "Epoch 85/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4980 - accuracy: 0.7021\n",
      "Epoch 86/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4917 - accuracy: 0.7071\n",
      "Epoch 87/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4788 - accuracy: 0.7088\n",
      "Epoch 88/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4943 - accuracy: 0.7206\n",
      "Epoch 89/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4948 - accuracy: 0.7235\n",
      "Epoch 90/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.5055 - accuracy: 0.7092\n",
      "Epoch 91/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.5401 - accuracy: 0.6916\n",
      "Epoch 92/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4823 - accuracy: 0.7143\n",
      "Epoch 93/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4997 - accuracy: 0.7197\n",
      "Epoch 94/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4782 - accuracy: 0.7126\n",
      "Epoch 95/100\n",
      "2380/2380 [==============================] - 4s 1ms/step - loss: 0.4667 - accuracy: 0.7202\n",
      "Epoch 96/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4869 - accuracy: 0.7055\n",
      "Epoch 97/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4642 - accuracy: 0.7223\n",
      "Epoch 98/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4669 - accuracy: 0.7223\n",
      "Epoch 99/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4818 - accuracy: 0.7122\n",
      "Epoch 100/100\n",
      "2380/2380 [==============================] - 3s 1ms/step - loss: 0.4848 - accuracy: 0.7113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x27ffea5fc18>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, epochs=100, batch_size=BATCH_SIZE,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest accauracy:\t0.9461 \n"
     ]
    }
   ],
   "source": [
    "test2_pred = np.argmax(model2.predict(X_test), axis=1)\n",
    "test_true = np.argmax(y_test, axis=1)\n",
    "np.unique(test2_pred)\n",
    "import sklearn.metrics as metrics\n",
    "print(\"\\tTest accauracy:\\t{:.4f} \".format(metrics.accuracy_score(test_true, test2_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2380, 240, 64)\n",
      "(1020, 240, 64)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
